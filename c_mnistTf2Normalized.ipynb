{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "c_mnistTf2Normalized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaishaliChetia/CapsNet-Keras/blob/master/c_mnistTf2Normalized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeoBe9bpMlPR"
      },
      "source": [
        "Original implementation at:\n",
        "\n",
        "https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb\n",
        "\n",
        "Geron's model doesn't use the keras functional API. In the keras functional API, you don't need to give the batchsize. \n",
        "\n",
        "When you print the model, you get this:\n",
        "\n",
        "```\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "_________________________________________________________________\n",
        "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
        "_________________________________________________________________\n",
        "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
        "_________________________________________________________________\n",
        "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
        "_________________________________________________________________\n",
        "reshape_layer_1 (Reshape)    (None, 1, 1152, 8)        0         \n",
        "_________________________________________________________________\n",
        "caps1_output_layer (SquashLa (None, 1, 1152, 8)        0         \n",
        "_________________________________________________________________\n",
        "Total params: 5,329,664\n",
        "Trainable params: 5,329,664\n",
        "Non-trainable params: 0\n",
        "```\n",
        "\n",
        "Notice that the Input-layer has shape (None, 28, 28, 1), but we only specified (28, 28, 1). It added None implicitly and that takes care of the batch.\n",
        "\n",
        "So for anywhere Geron uses the batch size explicitly, you don't need to do anything and tensorflow will take care of.\n",
        "\n",
        "Also note that tensorflow 1 APIs are still provided with the compat layer. I used the reduce_sum from TF1 in the squash layer, that allowed me to use Geron's code.\n",
        "\n",
        "Documentation on how to migrate from TF1 to TF2 can be found here:\n",
        "\n",
        "https://www.tensorflow.org/guide/migrate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY0OS1x1qLp2",
        "outputId": "479f7f3d-a536-437a-a69d-52ef31ff7e64"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCCmDd7lMlPU"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow.keras as K"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UydL5gJMlPV"
      },
      "source": [
        "caps1_n_maps = 32\n",
        "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
        "caps1_n_dims = 8\n",
        "caps2_n_caps = 10\n",
        "caps2_n_dims = 16\n",
        "\n",
        "tf.random.set_seed(500000)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sukwGEY4MlPV"
      },
      "source": [
        "class SquashLayer(K.layers.Layer):\n",
        "  def __init__(self, axis=-1, **kwargs):\n",
        "    super(SquashLayer, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "    \n",
        "  def build(self, input_shapes):\n",
        "    pass\n",
        "\n",
        "  def call(self, inputs):\n",
        "    EPSILON = 1.0e-9\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           axis=self.axis,\\\n",
        "                                           keepdims=True)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    squash_factor = squared_norm / (1. + squared_norm)\n",
        "    unit_vector = inputs / safe_norm\n",
        "    return squash_factor * unit_vector\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(SquashLayer, self).get_config()\n",
        "    config.update({\"axis\": self.axis})\n",
        "    return config\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_qIVI_u2i-s"
      },
      "source": [
        "class SafeNorm(K.layers.Layer):\n",
        "  \n",
        "  def __init__(self, axis=-1, keep_dims = False,  **kwargs):\n",
        "    super(SafeNorm, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "    self.keep_dims = keep_dims\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    pass\n",
        "\n",
        "  def call(self, input):\n",
        "    EPSILON = 1.0e-9\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           axis=self.axis,\\\n",
        "                                           keepdims= self.keep_dims)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    return safe_norm\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(SafeNorm, self).get_config()\n",
        "    config.update({\"axis\": self.axis, \"keep_dims\": self.keep_dims})\n",
        "    return config\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECOObckMlPW"
      },
      "source": [
        "# This should be the part where the digit layer, and where we tile things\n",
        "# This is incomplete, and work in progress\n",
        "# TODO: Complete this\n",
        "class MyDigitCapsLayer(K.layers.Layer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyDigitCapsLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    init_sigma = 0.1  # TODO: use\n",
        "    self.kernel = self.add_weight(\\\n",
        "                      \"kernel\",\\\n",
        "                      (caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\\\n",
        "                      initializer=\"random_normal\",\\\n",
        "                      dtype=tf.float32)\n",
        "\n",
        "  \n",
        "  # To debug this function, I used prints to print the shape\n",
        "  # expand_dims just adds an exis, so if you say expand_dims(inshape=(5, 3), -1),\n",
        "  # you get the output shape (5, 3, 1), it just adds an axis at the end\n",
        "  # Then tile just multiplies one of the dimensions (that is it stacks along that direction N times)\n",
        "  # so tile(inshape=(5, 3, 1), [1, 1, 1000]) will yield a shape (5, 3, 1000)\n",
        "  #\n",
        "  # Notice I didn't tile in build, but in call, Most probaly this is the right thing to do\n",
        "  # but we'll only figure out when we actually train\n",
        "  def call(self, inputs):\n",
        "    # Add a dimension at the end\n",
        "    exp1 = tf.expand_dims(inputs, -1, name=\"caps1_output_expanded\")\n",
        "    # add a dimension along 3rd axis\n",
        "    exp1 = tf.expand_dims(exp1, 2, name=\"caps2_output_espanced\")\n",
        "    # tile along 3rd axis\n",
        "    tile = tf.tile(exp1, [1, 1, caps2_n_caps, 1, 1], name=\"caps1_output_tiled\")\n",
        "    caps2_predicted = tf.matmul(self.kernel, tile, name=\"caps2_predicted\")\n",
        "    return caps2_predicted\n",
        "\n",
        "  def get_config(self):\n",
        "    return super(MyDigitCapsLayer, self).get_config()\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg6qxAU3h0hv"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss\n",
        "class MarginLoss(K.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "      super(MarginLoss, self).__init__(**kwargs)\n",
        "\n",
        "  \n",
        "    def get_config(self):\n",
        "      config = super(MarginLoss, self).get_config()\n",
        "      return config\n",
        "    \n",
        "    def safe_norm(self, input, axis=-2, epsilon=1e-7, keep_dims=False, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "    \n",
        "\n",
        "    def call(self,y_true, input):\n",
        "      # print(f\"y_true.shape = {y_true.shape}, y_pred.shape = {y_pred.shape}\")\n",
        "      # return K.losses.MeanSquaredError()(y_true, y_pred)\n",
        "\n",
        "      #y_true = K.Input(shape=[], dtype=tf.int64, name=\"y\")\n",
        "      m_plus = 0.9\n",
        "      m_minus = 0.1\n",
        "      lambda_ = 0.5 \n",
        "      \n",
        "      #y_true one hot encode y_train\n",
        "      T = tf.one_hot(y_true, depth=caps2_n_caps, name=\"T\")\n",
        "      \n",
        "      caps2_output_norm = self.safe_norm(input, keep_dims = True)\n",
        "\n",
        "      present_error_raw = tf.square(\\\n",
        "                                    tf.maximum(0., m_plus - caps2_output_norm),\n",
        "                                    name=\"present_error_raw\")\n",
        "      present_error = tf.reshape(\\\n",
        "                                    present_error_raw, shape=(-1, 10),\n",
        "                                    name=\"present_error\")  \n",
        "  \n",
        "      absent_error_raw = tf.square(\\\n",
        "                                    tf.maximum(0., caps2_output_norm - m_minus),\n",
        "                                    name=\"absent_error_raw\")\n",
        "      absent_error = tf.reshape(\\\n",
        "                                    absent_error_raw, shape=(-1, 10),\n",
        "                                    name=\"absent_error\")\n",
        "  \n",
        "      L = tf.add(\\\n",
        "                  T * present_error,\\\n",
        "                  lambda_ * (1.0 - T) * absent_error,\n",
        "                  name=\"L\")\n",
        "      marginLoss = tf.reduce_mean(\\\n",
        "                                  tf.reduce_sum(L, axis=1),\\\n",
        "                                  name=\"margin_loss\")\n",
        "      return marginLoss\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpXMBYOeWlDd"
      },
      "source": [
        "class RoutingByAgreement(K.layers.Layer):\n",
        "  def __init__(self, round_number=-1, **kwargs):\n",
        "    super(RoutingByAgreement, self).__init__(**kwargs)\n",
        "    self.round_number = round_number \n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(RoutingByAgreement, self).get_config()\n",
        "    config.update({\"round_number\": self.round_number})\n",
        "    return config\n",
        "\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    self.raw_weights_1 = self.add_weight(\"raw_weights\", \\\n",
        "                                         (caps1_n_caps, caps2_n_caps, 1, 1), \\\n",
        "                                         initializer = \"zeros\", \\\n",
        "                                         dtype=tf.float32,)\n",
        "    \n",
        "    #print(\"Routing layer: self.raw_weights = \", self.raw_weights.shape, \"input_shape = \", input_shapes)\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def squash(inputs):\n",
        "    EPSILON = 1.0e-7\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           keepdims=True)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    squash_factor = squared_norm / (1. + squared_norm)\n",
        "    unit_vector = inputs / safe_norm\n",
        "    return squash_factor * unit_vector\n",
        "\n",
        "  def single_round_routing(self, inputs, raw_weights, agreement):\n",
        "    raw_weights = tf.add(raw_weights, agreement)\n",
        "    routing_wt = tf.nn.softmax(raw_weights, axis=2)\n",
        "    wt_predictions = tf.multiply(routing_wt, inputs)\n",
        "    wt_sum = tf.reduce_sum(wt_predictions, axis=1, keepdims=True)\n",
        "    return wt_sum\n",
        "\n",
        "  def call(self, inputs):\n",
        "    agreement = tf.zeros(shape=self.raw_weights_1.shape)\n",
        "    sqsh_wt_sum = None\n",
        "    x = inputs\n",
        "    for i in range(2):\n",
        "      wt_sum = self.single_round_routing(inputs, self.raw_weights_1, agreement)\n",
        "      sqsh_wt_sum = RoutingByAgreement.squash(wt_sum)\n",
        "      sqsh_wt_sum_tiled = tf.tile(\\\n",
        "                          sqsh_wt_sum ,\\\n",
        "                          [1, caps1_n_caps, 1, 1, 1],\\\n",
        "                          name=\"caps2_output_round_1_tiled\")\n",
        "      agreement = tf.matmul(\\\n",
        "                            x, \\\n",
        "                            sqsh_wt_sum_tiled,\\\n",
        "                            transpose_a=True,\\\n",
        "                            name=\"agreement\")\n",
        "    return sqsh_wt_sum                           \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSEe-231jn49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219103f6-b3e2-49e0-fe5c-b1342f057708"
      },
      "source": [
        "(x_train, y_train,), (x_test, y_test) = K.datasets.mnist.load_data()\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcHaaMo8db4K"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#print(x_train[500])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnmSudqTMlPX",
        "outputId": "9edc7ce7-b73f-492f-d134-0278ec19ff80"
      },
      "source": [
        "class Model:\n",
        "    @staticmethod\n",
        "    def build(inshape=(28, 28, 1)):\n",
        "        inp = K.Input(shape=inshape, dtype=tf.float32, name='input')\n",
        "        \n",
        "        # Primary capsules\n",
        "        # For each digit in the batch\n",
        "        # 32 maps, each 6x6 grid of 8 dimensional vectors\n",
        "        \n",
        "        # First Conv layer\n",
        "        conv1_params = \\\n",
        "        {\n",
        "            \"filters\": 256,\n",
        "            \"kernel_size\": 9,\n",
        "            \"strides\": 1,\n",
        "            \"padding\": \"valid\",\n",
        "            \"activation\": tf.nn.relu,\n",
        "        }\n",
        "        x = K.layers.Conv2D(**conv1_params, name=\"conv_layer_1\")(inp)\n",
        "        \n",
        "        # Second conv layer\n",
        "        conv2_params = \\\n",
        "        {\n",
        "            \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
        "            \"kernel_size\": 9,\n",
        "            \"strides\": 2,\n",
        "            \"padding\": \"valid\",\n",
        "            \"activation\": tf.nn.relu\n",
        "        }\n",
        "        x = K.layers.Conv2D(**conv2_params, name=\"conv_layer_2\")(x)\n",
        "        \n",
        "        # Reshape\n",
        "        x = K.layers.Reshape(\\\n",
        "                             (caps1_n_caps, caps1_n_dims),\\\n",
        "                             name=\"reshape_layer_1\")(x)\n",
        "                             \n",
        "        x = SquashLayer(name=\"caps1_output_layer\")(x)\n",
        "        \n",
        "        x = MyDigitCapsLayer(name = \"caps2_predicted\")(x)\n",
        "        caps2_predicted = x # Save this value for later\n",
        "        \n",
        "        #routing by agreement (2 rounds)\n",
        "        x = RoutingByAgreement(name=\"routing1\", round_number=2)(x)\n",
        "        \n",
        "        return K.Model(inputs=inp, outputs=x, name='my')\n",
        "    \n",
        "m = Model.build()\n",
        "print(m.summary())\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
            "_________________________________________________________________\n",
            "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
            "_________________________________________________________________\n",
            "reshape_layer_1 (Reshape)    (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps1_output_layer (SquashLa (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps2_predicted (MyDigitCaps (None, 1152, 10, 16, 1)   1474560   \n",
            "_________________________________________________________________\n",
            "routing1 (RoutingByAgreement (None, 1, 10, 16, 1)      11520     \n",
            "=================================================================\n",
            "Total params: 6,815,744\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw3j_zWQMlPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967dfad9-cd0e-4951-d59a-d22267c2461d"
      },
      "source": [
        "y_train_train = tf.one_hot(y_train, depth=caps2_n_caps, name=\"T\")\n",
        "print(y_train_train.shape)\n",
        "#print(y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zxRXCYIz_HQ"
      },
      "source": [
        "class MyAccuracy(K.metrics.Metric):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyAccuracy, self).__init__(**kwargs)\n",
        "    self.acc_obj = None\n",
        "    self.state = 0\n",
        "  \n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(MyAccuracy, self).get_config()\n",
        "    config.update({\"acc_obj\": None, \"state\": self.state})\n",
        "    return config\n",
        "\n",
        "\n",
        "  def safe_norm(self, input, axis=-2, epsilon=1e-7, keep_dims=True, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "  def update_state(self, y_true, input, sample_weight=None):\n",
        "    if self.acc_obj is None:\n",
        "      self.acc_obj = K.metrics.Accuracy()\n",
        "    y_proba = self.safe_norm(input, axis=-2)\n",
        "    y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
        "    y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "    y_true = tf.reshape(y_true, (y_true.shape[0], ))\n",
        "    y_true = tf.cast(y_true, dtype=tf.int64)\n",
        "    self.acc_obj.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.acc_obj.reset_state()\n",
        "\n",
        "  def result(self):\n",
        "    return self.acc_obj.result()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohNmlixkrAek"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "comparison_metric = MyAccuracy()\n",
        "#checkpoint_filepath = \"/content/drive/MyDrive/Weights/weights-improvement-{epoch:02d}-{val_my_accuracy:.2f}.hdf5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"/content/drive/MyDrive/WeightsMnist/11_best_weights1.hdf5\",\n",
        "        save_weights_only=True,\n",
        "        monitor=f\"val_{comparison_metric.name}\",\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"/content/drive/MyDrive/WeightsMnist/11_latest_weights1.hdf5\",\n",
        "        save_weights_only=True,\n",
        "        monitor=f\"val_{comparison_metric.name}\",\n",
        "        mode='max',\n",
        "        save_best_only=False)\n",
        "log_csv = CSVLogger(\"/content/drive/MyDrive/WeightsMnist/11_mylogs1.csv\", separator = \",\", append = False)\n",
        "callback_list = [model_checkpoint_callback, model_checkpoint_callback2, log_csv]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cahMgtOqMlPa"
      },
      "source": [
        "m.compile(optimizer='adam', loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "history = m.fit(x_train, y_train, batch_size=32, epochs=2, verbose= 1, validation_split=0.2, callbacks = callback_list)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyUFx-dcMlPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "outputId": "b0fffd32-2c91-49eb-e7f6-7d383d673cab"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (30, 10)\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "ax[0].plot(history.history['my_accuracy_1'])\n",
        "ax[0].plot(history.history['val_my_accuracy_1'])\n",
        "ax[0].set_title('Model Accuracy')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].legend(['Training Accuracy', 'Validation Accuracy'], loc='best')\n",
        "\n",
        "ax[1].plot(history.history['loss'])\n",
        "ax[1].plot(history.history['val_loss'])\n",
        "ax[1].set_title('Model Loss')\n",
        "ax[1].set_ylabel('Loss')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].legend(['Training Loss', 'Validation Loss'], loc='best')\n",
        "plt.show()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-3030579c04ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'my_accuracy_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_my_accuracy_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2160x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnBQabNNKLH"
      },
      "source": [
        "print(f'Best Validation Accuracy = {np.max(history.history[\"val_my_accuracy_1\"])}')\n",
        "print(f'Best Training   Accuracy = {np.max(history.history[\"my_accuracy_1\"])}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pOcuSJGSvLY"
      },
      "source": [
        "\n",
        "m.save(\"/content/drive/MyDrive/WeightsMnist/save.tf\", save_format='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLeqoVJkjPKB"
      },
      "source": [
        "#Extra layer for evaluate\n",
        "class DimensionCorrection(K.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "      super(DimensionCorrection, self).__init__(**kwargs)\n",
        "    \n",
        "    def safe_norm(self, input, axis=-2, epsilon=1e-7, keep_dims=False, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "    def call(self,y_pred):\n",
        "      y_proba = self.safe_norm(y_pred, axis=-2)\n",
        "      y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
        "      y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "      return y_pred\n",
        "\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3s5KL2po5FN",
        "outputId": "b596dfb9-e99a-4612-d596-90ac73cb004b"
      },
      "source": [
        "y_test = tf.cast(y_test, dtype= tf.int64)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "8cJcH3YlsAVt",
        "outputId": "0b4f9bca-a978-4fc8-8fda-d13e76db066c"
      },
      "source": [
        "m = Model.build()\n",
        "m.load_weights('/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5')\n",
        "m.compile(optimizer='Adam', loss=MarginLoss)\n",
        "newmodel = K.models.Sequential(\\\n",
        "            [\\\n",
        "             m,\\\n",
        "             DimensionCorrection(),\\\n",
        "            ]\\\n",
        ")\n",
        "newmodel.summary()\n",
        "m.trainable = False\n",
        "newmodel.compile(optimizer='adam')\n",
        "\n",
        "y_pred = newmodel.predict(x_test)\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(f\"accuracy = {accuracy_score(y_test, y_pred)}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "initial y_pred = (None, 1, 10, 16, 1)\n",
            "final y_pred = (None,)\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "my (Functional)              (None, 1, 10, 16, 1)      6815744   \n",
            "_________________________________________________________________\n",
            "dimension_correction_19 (Dim (None,)                   0         \n",
            "=================================================================\n",
            "Total params: 6,815,744\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "initial y_pred = (None, 1, 10, 16, 1)\n",
            "final y_pred = (None,)\n",
            "[[ 961   15    0    0    0    0    3    1    0    0]\n",
            " [   0 1135    0    0    0    0    0    0    0    0]\n",
            " [   0   44  977    4    0    0    1    6    0    0]\n",
            " [   0    1    0 1005    0    1    0    3    0    0]\n",
            " [   0  189    0    0  785    0    6    0    0    2]\n",
            " [   0   48    0   19    0  818    6    1    0    0]\n",
            " [   1   12    0    0    0    0  945    0    0    0]\n",
            " [   0   16    2    1    0    0    0 1009    0    0]\n",
            " [   0   48    0    6    0    0    2    2  914    2]\n",
            " [   2   55    0    6    0    0    1    3    0  942]]\n",
            "accuracy = 0.9491\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-88302dc22f86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"accuracy = {accuracy_score(y_test, y_pred)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \"\"\"\n\u001b[1;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 771\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    534\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    535\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbZNCJZkZ46"
      },
      "source": [
        "y_pred_eval = DimensionCorrection()\n",
        "m2 = Model.build()\n",
        "m2.load_weights('/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-vE6yGAoBPI"
      },
      "source": [
        "m3 = K.models.Sequential()\n",
        "m3.add(m2)\n",
        "m3.add(y_pred_eval)\n",
        "m3.build()\n",
        "m3.compile(optimizer='adam', loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "m3.evaluate(x_test, y_test, batch_size= 32, verbose= 1)\n",
        "\n",
        "#m3.evaluate(x_test, y_test, batch_size= 32, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9vf-xeFUcgi"
      },
      "source": [
        "#converter = tf.lite.TFLiteConverter.from_keras_model(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuULPnldermd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdrYq9SwUr-N"
      },
      "source": [
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "# quantize_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5Vm_QpbUry8",
        "outputId": "0ed2fc82-702e-415e-a578-21da15a79b43"
      },
      "source": [
        "mm = K.models.load_model('/content/drive/MyDrive/WeightsMnist/save.tf',\\\n",
        "                         custom_objects=\\\n",
        "                          {\\\n",
        "                              \"SquashLayer\": SquashLayer,\\\n",
        "                              \"SafeNorm\": SafeNorm,\\\n",
        "                              \"MyDigitCapsLayer\": MyDigitCapsLayer,\\\n",
        "                              \"RoutingByAgreement\": RoutingByAgreement,\\\n",
        "                              \"MyAccuracy\": MyAccuracy,\\\n",
        "                              \"MarginLoss\": MarginLoss,\\\n",
        "                          })\n",
        "print(type(mm), mm.summary())\n",
        "print(mm.weights[0][0][0][0][0:5])\n",
        "e = mm.load_weights('/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5')\n",
        "print(mm.weights[0][0][0][0][0:5])\n",
        "\n",
        "\n",
        "# Create the .tflite file\n",
        "tflite_model_file = \"/content/drive/MyDrive/WeightsMnist/compressed.tflite\"\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
            "_________________________________________________________________\n",
            "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
            "_________________________________________________________________\n",
            "reshape_layer_1 (Reshape)    (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps1_output_layer (SquashLa (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps2_predicted (MyDigitCaps (None, 1152, 10, 16, 1)   1474560   \n",
            "_________________________________________________________________\n",
            "routing1 (RoutingByAgreement (None, 1, 10, 16, 1)      11520     \n",
            "=================================================================\n",
            "Total params: 6,815,744\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<class 'tensorflow.python.keras.engine.functional.Functional'> None\n",
            "tf.Tensor([-0.01821406 -0.02564497 -0.05699345 -0.01358504 -0.01916237], shape=(5,), dtype=float32)\n",
            "tf.Tensor([ 0.06499811 -0.099627   -1.0019162  -0.53550017 -0.03201126], shape=(5,), dtype=float32)\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpk_ihts3a/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpk_ihts3a/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1c026FiF3Hb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVrB1GkTFItQ",
        "outputId": "03fe35c9-ab59-4f96-848c-7fdc97f6f0d6"
      },
      "source": [
        "!du -sh /content/drive/MyDrive/WeightsMnist/*\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27M\t/content/drive/MyDrive/WeightsMnist/11_latest_weights1.hdf5\n",
            "512\t/content/drive/MyDrive/WeightsMnist/11_mylogs1.csv\n",
            "11M\t/content/drive/MyDrive/WeightsMnist/compressed.tflite\n",
            "27M\t/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5\n",
            "5.5K\t/content/drive/MyDrive/WeightsMnist/mylogs1.csv\n",
            "1.0K\t/content/drive/MyDrive/WeightsMnist/save.h5\n",
            "79M\t/content/drive/MyDrive/WeightsMnist/save.tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTzAAQHpL51b"
      },
      "source": [
        "# Use this tutorial for pruning\n",
        "quantization has already been done earlier\n",
        "\n",
        "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJLicHf3J1G-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}