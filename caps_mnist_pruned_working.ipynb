{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "c_mnistTf2Normalized.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BaishaliChetia/CapsNet-Keras/blob/master/caps_mnist_pruned_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeoBe9bpMlPR"
      },
      "source": [
        "Original implementation at:\n",
        "\n",
        "https://github.com/ageron/handson-ml/blob/master/extra_capsnets.ipynb\n",
        "\n",
        "Geron's model doesn't use the keras functional API. In the keras functional API, you don't need to give the batchsize. \n",
        "\n",
        "When you print the model, you get this:\n",
        "\n",
        "```\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "_________________________________________________________________\n",
        "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
        "_________________________________________________________________\n",
        "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
        "_________________________________________________________________\n",
        "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
        "_________________________________________________________________\n",
        "reshape_layer_1 (Reshape)    (None, 1, 1152, 8)        0         \n",
        "_________________________________________________________________\n",
        "caps1_output_layer (SquashLa (None, 1, 1152, 8)        0         \n",
        "_________________________________________________________________\n",
        "Total params: 5,329,664\n",
        "Trainable params: 5,329,664\n",
        "Non-trainable params: 0\n",
        "```\n",
        "\n",
        "Notice that the Input-layer has shape (None, 28, 28, 1), but we only specified (28, 28, 1). It added None implicitly and that takes care of the batch.\n",
        "\n",
        "So for anywhere Geron uses the batch size explicitly, you don't need to do anything and tensorflow will take care of.\n",
        "\n",
        "Also note that tensorflow 1 APIs are still provided with the compat layer. I used the reduce_sum from TF1 in the squash layer, that allowed me to use Geron's code.\n",
        "\n",
        "Documentation on how to migrate from TF1 to TF2 can be found here:\n",
        "\n",
        "https://www.tensorflow.org/guide/migrate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY0OS1x1qLp2",
        "outputId": "a14a5db4-2b93-482f-ff3f-d0272fad7baa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCCmDd7lMlPU"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow.keras as K\n",
        "import tensorflow_model_optimization as tfmot"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UydL5gJMlPV"
      },
      "source": [
        "caps1_n_maps = 32\n",
        "caps1_n_caps = caps1_n_maps * 6 * 6  # 1152 primary capsules\n",
        "caps1_n_dims = 8\n",
        "caps2_n_caps = 10\n",
        "caps2_n_dims = 16\n",
        "\n",
        "tf.random.set_seed(500000)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sukwGEY4MlPV"
      },
      "source": [
        "#class SquashLayer(K.layers.Layer, tfmot.sparsity.keras.PrunableLayer):\n",
        "class SquashLayer(K.layers.Layer):\n",
        "  def __init__(self, axis=-1, **kwargs):\n",
        "    super(SquashLayer, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "    \n",
        "  def build(self, input_shapes):\n",
        "    pass\n",
        "\n",
        "  \"\"\"\n",
        "  def get_prunable_weights(self):\n",
        "    return []\n",
        "  \"\"\"\n",
        "\n",
        "  def call(self, inputs):\n",
        "    EPSILON = 1.0e-9\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           axis=self.axis,\\\n",
        "                                           keepdims=True)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    squash_factor = squared_norm / (1. + squared_norm)\n",
        "    unit_vector = inputs / safe_norm\n",
        "    return squash_factor * unit_vector\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(SquashLayer, self).get_config()\n",
        "    config.update({\"axis\": self.axis})\n",
        "    return config\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_qIVI_u2i-s"
      },
      "source": [
        "#class SafeNorm(K.layers.Layer, tfmot.sparsity.keras.PrunableLayer):\n",
        "class SafeNorm(K.layers.Layer):\n",
        "  \n",
        "  def __init__(self, axis=-1, keep_dims = False,  **kwargs):\n",
        "    super(SafeNorm, self).__init__(**kwargs)\n",
        "    self.axis = axis\n",
        "    self.keep_dims = keep_dims\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    pass\n",
        "\n",
        "  \"\"\"\n",
        "  def get_prunable_weights(self):\n",
        "    return []\n",
        "  \"\"\"\n",
        "\n",
        "  def call(self, input):\n",
        "    EPSILON = 1.0e-9\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           axis=self.axis,\\\n",
        "                                           keepdims= self.keep_dims)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    return safe_norm\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(SafeNorm, self).get_config()\n",
        "    config.update({\"axis\": self.axis, \"keep_dims\": self.keep_dims})\n",
        "    return config\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qECOObckMlPW"
      },
      "source": [
        "# This should be the part where the digit layer, and where we tile things\n",
        "# This is incomplete, and work in progress\n",
        "# TODO: Complete this\n",
        "class MyDigitCapsLayer(K.layers.Layer, tfmot.sparsity.keras.PrunableLayer):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyDigitCapsLayer, self).__init__(**kwargs)\n",
        "  \n",
        "  def get_config(self):\n",
        "    config =  super(MyDigitCapsLayer, self).get_config()\n",
        "    return config\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    init_sigma = 0.1  # TODO: use\n",
        "    self.kernel = self.add_weight(\\\n",
        "                      \"kernel\",\\\n",
        "                      (caps1_n_caps, caps2_n_caps, caps2_n_dims, caps1_n_dims),\\\n",
        "                      initializer=\"random_normal\",\\\n",
        "                      dtype=tf.float32)\n",
        "\n",
        "  \n",
        "  # To debug this function, I used prints to print the shape\n",
        "  # expand_dims just adds an exis, so if you say expand_dims(inshape=(5, 3), -1),\n",
        "  # you get the output shape (5, 3, 1), it just adds an axis at the end\n",
        "  # Then tile just multiplies one of the dimensions (that is it stacks along that direction N times)\n",
        "  # so tile(inshape=(5, 3, 1), [1, 1, 1000]) will yield a shape (5, 3, 1000)\n",
        "  #\n",
        "  # Notice I didn't tile in build, but in call, Most probaly this is the right thing to do\n",
        "  # but we'll only figure out when we actually train\n",
        "  def get_prunable_weights(self):\n",
        "    return [self.kernel]\n",
        "  \n",
        "  def call(self, inputs):\n",
        "    # Add a dimension at the end\n",
        "    exp1 = tf.expand_dims(inputs, -1, name=\"caps1_output_expanded\")\n",
        "    # add a dimension along 3rd axis\n",
        "    exp1 = tf.expand_dims(exp1, 2, name=\"caps2_output_espanced\")\n",
        "    # tile along 3rd axis\n",
        "    tile = tf.tile(exp1, [1, 1, caps2_n_caps, 1, 1], name=\"caps1_output_tiled\")\n",
        "    caps2_predicted = tf.matmul(self.kernel, tile, name=\"caps2_predicted\")\n",
        "    return caps2_predicted\n",
        "\n",
        "  \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg6qxAU3h0hv"
      },
      "source": [
        "# https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss\n",
        "class MarginLoss(K.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "      super(MarginLoss, self).__init__(**kwargs)\n",
        "\n",
        "  \n",
        "    def get_config(self):\n",
        "      config = super(MarginLoss, self).get_config()\n",
        "      return config\n",
        "    \n",
        "    def safe_norm(self, input, axis=-2, epsilon=1e-5, keep_dims=False, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "    \"\"\"\n",
        "    def get_prunable_weights(self):\n",
        "      return []\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self,y_true, input):\n",
        "      # print(f\"y_true.shape = {y_true.shape}, y_pred.shape = {y_pred.shape}\")\n",
        "      # return K.losses.MeanSquaredError()(y_true, y_pred)\n",
        "\n",
        "      #y_true = K.Input(shape=[], dtype=tf.int64, name=\"y\")\n",
        "      m_plus = 0.9\n",
        "      m_minus = 0.1\n",
        "      lambda_ = 0.5 \n",
        "      \n",
        "      #y_true one hot encode y_train\n",
        "      T = tf.one_hot(y_true, depth=caps2_n_caps, name=\"T\")\n",
        "      \n",
        "      caps2_output_norm = self.safe_norm(input, keep_dims = True)\n",
        "\n",
        "      present_error_raw = tf.square(\\\n",
        "                                    tf.maximum(0., m_plus - caps2_output_norm),\n",
        "                                    name=\"present_error_raw\")\n",
        "      present_error = tf.reshape(\\\n",
        "                                    present_error_raw, shape=(-1, 10),\n",
        "                                    name=\"present_error\")  \n",
        "  \n",
        "      absent_error_raw = tf.square(\\\n",
        "                                    tf.maximum(0., caps2_output_norm - m_minus),\n",
        "                                    name=\"absent_error_raw\")\n",
        "      absent_error = tf.reshape(\\\n",
        "                                    absent_error_raw, shape=(-1, 10),\n",
        "                                    name=\"absent_error\")\n",
        "  \n",
        "      L = tf.add(\\\n",
        "                  T * present_error,\\\n",
        "                  lambda_ * (1.0 - T) * absent_error,\n",
        "                  name=\"L\")\n",
        "      marginLoss = tf.reduce_mean(\\\n",
        "                                  tf.reduce_sum(L, axis=1),\\\n",
        "                                  name=\"margin_loss\")\n",
        "      return marginLoss\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpXMBYOeWlDd"
      },
      "source": [
        "#class RoutingByAgreement(K.layers.Layer, tfmot.sparsity.keras.PrunableLayer):\n",
        "class RoutingByAgreement(K.layers.Layer):\n",
        "  def __init__(self, round_number=-1, **kwargs):\n",
        "    super(RoutingByAgreement, self).__init__(**kwargs)\n",
        "    self.round_number = round_number \n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(RoutingByAgreement, self).get_config()\n",
        "    config.update({\"round_number\": self.round_number})\n",
        "    return config\n",
        "\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    self.raw_weights_1 = self.add_weight(\"raw_weights\", \\\n",
        "                                         (caps1_n_caps, caps2_n_caps, 1, 1), \\\n",
        "                                         initializer = \"zeros\", \\\n",
        "                                         dtype=tf.float32,)\n",
        "    \n",
        "    #print(\"Routing layer: self.raw_weights = \", self.raw_weights.shape, \"input_shape = \", input_shapes)\n",
        "\n",
        "  \"\"\"\n",
        "  def get_prunable_weights(self):\n",
        "    return [self.raw_weights_1]\n",
        "  \"\"\"\n",
        "\n",
        "  @staticmethod\n",
        "  def squash(inputs):\n",
        "    EPSILON = 1.0e-5\n",
        "    squared_norm = tf.compat.v1.reduce_sum(tf.square(inputs),\\\n",
        "                                           keepdims=True)\n",
        "    safe_norm = tf.sqrt(squared_norm + EPSILON)\n",
        "    squash_factor = squared_norm / (1. + squared_norm)\n",
        "    unit_vector = inputs / safe_norm\n",
        "    return squash_factor * unit_vector\n",
        "\n",
        "  def single_round_routing(self, inputs, raw_weights, agreement):\n",
        "    raw_weights = tf.add(raw_weights, agreement)\n",
        "    routing_wt = tf.nn.softmax(raw_weights, axis=2)\n",
        "    wt_predictions = tf.multiply(routing_wt, inputs)\n",
        "    wt_sum = tf.reduce_sum(wt_predictions, axis=1, keepdims=True)\n",
        "    return wt_sum\n",
        "\n",
        "  def call(self, inputs):\n",
        "    agreement = tf.zeros(shape=self.raw_weights_1.shape)\n",
        "    sqsh_wt_sum = None\n",
        "    x = inputs\n",
        "    for i in range(2):\n",
        "      wt_sum = self.single_round_routing(inputs, self.raw_weights_1, agreement)\n",
        "      sqsh_wt_sum = RoutingByAgreement.squash(wt_sum)\n",
        "      sqsh_wt_sum_tiled = tf.tile(\\\n",
        "                          sqsh_wt_sum ,\\\n",
        "                          [1, caps1_n_caps, 1, 1, 1],\\\n",
        "                          name=\"caps2_output_round_1_tiled\")\n",
        "      agreement = tf.matmul(\\\n",
        "                            x, \\\n",
        "                            sqsh_wt_sum_tiled,\\\n",
        "                            transpose_a=True,\\\n",
        "                            name=\"agreement\")\n",
        "    return sqsh_wt_sum                           \n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSEe-231jn49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4094375-7a2f-4dd7-e4c1-5c99a906d98c"
      },
      "source": [
        "(x_train, y_train,), (x_test, y_test) = K.datasets.mnist.load_data()\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcHaaMo8db4K"
      },
      "source": [
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0\n",
        "\n",
        "#print(x_train[500])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnmSudqTMlPX",
        "outputId": "d8cb4bdf-22e9-45fb-b7eb-e8506f355018"
      },
      "source": [
        "class Model:\n",
        "    @staticmethod\n",
        "    def build(inshape=(28, 28, 1)):\n",
        "        inp = K.Input(shape=inshape, dtype=tf.float32, name='input')\n",
        "        \n",
        "        # Primary capsules\n",
        "        # For each digit in the batch\n",
        "        # 32 maps, each 6x6 grid of 8 dimensional vectors\n",
        "        \n",
        "        # First Conv layer\n",
        "        conv1_params = \\\n",
        "        {\n",
        "            \"filters\": 256,\n",
        "            \"kernel_size\": 9,\n",
        "            \"strides\": 1,\n",
        "            \"padding\": \"valid\",\n",
        "            \"activation\": tf.nn.relu,\n",
        "        }\n",
        "        x = K.layers.Conv2D(**conv1_params, name=\"conv_layer_1\")(inp)\n",
        "        \n",
        "        # Second conv layer\n",
        "        conv2_params = \\\n",
        "        {\n",
        "            \"filters\": caps1_n_maps * caps1_n_dims, # 256 convolutional filters\n",
        "            \"kernel_size\": 9,\n",
        "            \"strides\": 2,\n",
        "            \"padding\": \"valid\",\n",
        "            \"activation\": tf.nn.relu\n",
        "        }\n",
        "        x = K.layers.Conv2D(**conv2_params, name=\"conv_layer_2\")(x)\n",
        "        \n",
        "        # Reshape\n",
        "        x = K.layers.Reshape(\\\n",
        "                             (caps1_n_caps, caps1_n_dims),\\\n",
        "                             name=\"reshape_layer_1\")(x)\n",
        "                             \n",
        "        x = SquashLayer(name=\"caps1_output_layer\")(x)\n",
        "        \n",
        "        x = MyDigitCapsLayer(name = \"caps2_predicted\")(x)\n",
        "        caps2_predicted = x # Save this value for later\n",
        "        \n",
        "        #routing by agreement (2 rounds)\n",
        "        x = RoutingByAgreement(name=\"routing1\", round_number=2)(x)\n",
        "        \n",
        "        return K.Model(inputs=inp, outputs=x, name='my')\n",
        "    \n",
        "m = Model.build()\n",
        "print(m.summary())\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
            "_________________________________________________________________\n",
            "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
            "_________________________________________________________________\n",
            "reshape_layer_1 (Reshape)    (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps1_output_layer (SquashLa (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps2_predicted (MyDigitCaps (None, 1152, 10, 16, 1)   1474560   \n",
            "_________________________________________________________________\n",
            "routing1 (RoutingByAgreement (None, 1, 10, 16, 1)      11520     \n",
            "=================================================================\n",
            "Total params: 6,815,744\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw3j_zWQMlPZ"
      },
      "source": [
        "# y_train_train = tf.one_hot(y_train, depth=caps2_n_caps, name=\"T\")\n",
        "# print(y_train_train.shape)\n",
        "# #print(y_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zxRXCYIz_HQ"
      },
      "source": [
        "class MyAccuracy(K.metrics.Metric):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(MyAccuracy, self).__init__(**kwargs)\n",
        "    self.acc_obj = K.metrics.Accuracy()\n",
        "    self.state = 0\n",
        "  \n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(MyAccuracy, self).get_config()\n",
        "    config.update({\"acc_obj\": None, \"state\": self.state})\n",
        "    return config\n",
        "\n",
        "\n",
        "  def safe_norm(self, input, axis=-2, epsilon=1e-5, keep_dims=True, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "  def update_state(self, y_true, input, sample_weight=None):\n",
        "    if self.acc_obj is None:\n",
        "      self.acc_obj = K.metrics.Accuracy()\n",
        "    y_proba = self.safe_norm(input, axis=-2)\n",
        "    y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
        "    y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "    #y_true = tf.reshape(y_true, (y_true.shape[0], ))\n",
        "    y_true = tf.cast(y_true, dtype=tf.int64)\n",
        "    self.acc_obj.update_state(y_true, y_pred, sample_weight)\n",
        "\n",
        "  def reset_state(self):\n",
        "    self.acc_obj.reset_state()\n",
        "\n",
        "  def result(self):\n",
        "    return self.acc_obj.result()\n",
        "\n",
        "class MyReshapeLayer(K.layers.Layer):\n",
        "  def __init__(self, axis=-1, keep_dims = False,  **kwargs):\n",
        "    super(MyReshapeLayer, self).__init__(**kwargs)\n",
        "\n",
        "  def build(self, input_shapes):\n",
        "    pass\n",
        "\n",
        "  def safe_norm(self, input, axis=-2, epsilon=1e-5, keep_dims=True, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "  def call(self, input):\n",
        "    print('printing shapes ------------------- ')\n",
        "    EPSILON = 1.0e-9\n",
        "    print(input)\n",
        "    y_proba = self.safe_norm(input, axis=-2)\n",
        "    print(y_proba)\n",
        "    y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
        "    print(y_proba_argmax)\n",
        "    y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "    print(y_pred)\n",
        "    return tf.cast(y_pred, tf.int64)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super(MyReshapeLayer, self).get_config()\n",
        "    return config"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohNmlixkrAek"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "comparison_metric = MyAccuracy()\n",
        "#checkpoint_filepath = \"/content/drive/MyDrive/Weights/weights-improvement-{epoch:02d}-{val_my_accuracy:.2f}.hdf5\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"/content/drive/MyDrive/WeightsMnist/11_best_weights1.hdf5\",\n",
        "        save_weights_only=True,\n",
        "        monitor=f\"val_{comparison_metric.name}\",\n",
        "        mode='max',\n",
        "        save_best_only=True)\n",
        "model_checkpoint_callback2 = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = \"/content/drive/MyDrive/WeightsMnist/11_latest_weights1.hdf5\",\n",
        "        save_weights_only=True,\n",
        "        monitor=f\"val_{comparison_metric.name}\",\n",
        "        mode='max',\n",
        "        save_best_only=False)\n",
        "log_csv = CSVLogger(\"/content/drive/MyDrive/WeightsMnist/11_mylogs1.csv\", separator = \",\", append = False)\n",
        "callback_list = [model_checkpoint_callback, model_checkpoint_callback2, log_csv]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "-mb3hJfK4YnA",
        "outputId": "7be14b46-6931-42d3-d972-4ec40bb28901"
      },
      "source": [
        "comparison_metric.name"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'my_accuracy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZFYZzGt4YXz"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cahMgtOqMlPa"
      },
      "source": [
        "m.compile(optimizer='adam', loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "#history = m.fit(x_train, y_train, batch_size=32, epochs=1, verbose= 1, validation_split=0.2, callbacks = callback_list)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bnBQabNNKLH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "60486f24-3fed-49de-c591-f43efed39e45"
      },
      "source": [
        "print(f'Best Validation Accuracy = {np.max(history.history[\"val_my_accuracy_3\"])}')\n",
        "print(f'Best Training   Accuracy = {np.max(history.history[\"my_accuracy_3\"])}')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-8b89d1f385f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best Validation Accuracy = {np.max(history.history[\"val_my_accuracy_3\"])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Best Training   Accuracy = {np.max(history.history[\"my_accuracy_3\"])}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pOcuSJGSvLY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d56424ef-0a67-469e-932e-fe2ec0b2a44a"
      },
      "source": [
        "#m.save(\"/content/drive/MyDrive/WeightsMnist/save.tf\", save_format='tf')\n",
        "\n",
        "# \n",
        "!rm -f \"/content/drive/MyDrive/WeightsMnist/save3.tf\""
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/drive/MyDrive/WeightsMnist/save3.tf': Is a directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SM-gwDR2FtA"
      },
      "source": [
        "m.save(\"/content/drive/MyDrive/WeightsMnist/save3.tf\", save_format='tf')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLeqoVJkjPKB"
      },
      "source": [
        "#Extra layer for evaluate\n",
        "class DimensionCorrection(K.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "      super(DimensionCorrection, self).__init__(**kwargs)\n",
        "    \n",
        "    def safe_norm(self, input, axis=-2, epsilon=1e-7, keep_dims=False, name=None):\n",
        "      squared_norm = tf.reduce_sum(tf.square(input), axis=axis,\n",
        "                                     keepdims=keep_dims)\n",
        "      return tf.sqrt(squared_norm + epsilon)\n",
        "\n",
        "    def call(self,y_pred):\n",
        "      y_proba = self.safe_norm(y_pred, axis=-2)\n",
        "      y_proba_argmax = tf.argmax(y_proba, axis=2)\n",
        "      y_pred = tf.squeeze(y_proba_argmax, axis=[1,2], name=\"y_pred\")\n",
        "      return y_pred\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3s5KL2po5FN"
      },
      "source": [
        "y_test = tf.cast(y_test, dtype= tf.int64)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cJcH3YlsAVt"
      },
      "source": [
        "def ignore():\n",
        "  m = Model.build()\n",
        "  m.load_weights('/content/drive/MyDrive/WeightsMnist/11_latest_weights1.hdf5')\n",
        "  m.compile(optimizer='Adam', loss=MarginLoss)\n",
        "  newmodel = K.models.Sequential(\\\n",
        "              [\\\n",
        "              m,\\\n",
        "              DimensionCorrection(),\\\n",
        "              ]\\\n",
        "  )\n",
        "  newmodel.summary()\n",
        "  m.trainable = False\n",
        "  newmodel.compile(optimizer='adam')\n",
        "\n",
        "  y_pred = newmodel.predict(x_test)\n",
        "\n",
        "  import sklearn\n",
        "  from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
        "  print(confusion_matrix(y_test, y_pred))\n",
        "  print(f\"accuracy = {accuracy_score(y_test, y_pred)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJLicHf3J1G-"
      },
      "source": [
        "mm = K.models.load_model('/content/drive/MyDrive/WeightsMnist/save2.tf',\\\n",
        "                         custom_objects=\\\n",
        "                          {\\\n",
        "                              \"SquashLayer\": SquashLayer,\\\n",
        "                              \"SafeNorm\": SafeNorm,\\\n",
        "                              \"MyDigitCapsLayer\": MyDigitCapsLayer,\\\n",
        "                              \"RoutingByAgreement\": RoutingByAgreement,\\\n",
        "                              \"MyAccuracy\": MyAccuracy,\\\n",
        "                              \"MarginLoss\": MarginLoss,\\\n",
        "                          })\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbZNCJZkZ46"
      },
      "source": [
        "# y_pred_eval = DimensionCorrection()\n",
        "# m2 = Model.build()\n",
        "# m2.load_weights('/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-vE6yGAoBPI"
      },
      "source": [
        "# m3 = K.models.Sequential()\n",
        "# m3.add(m2)\n",
        "# m3.add(y_pred_eval)\n",
        "# m3.build()\n",
        "# m3.compile(optimizer='adam', loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "# m3.evaluate(x_test, y_test, batch_size= 32, verbose= 1)\n",
        "\n",
        "# #m3.evaluate(x_test, y_test, batch_size= 32, verbose= 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9vf-xeFUcgi"
      },
      "source": [
        "#converter = tf.lite.TFLiteConverter.from_keras_model(m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VuULPnldermd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdrYq9SwUr-N"
      },
      "source": [
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# converter.target_spec.supported_types = [tf.float16]\n",
        "# quantize_model = converter.convert()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWt9eE4hpaDy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5Vm_QpbUry8"
      },
      "source": [
        "# mm = K.models.load_model('/content/drive/MyDrive/WeightsMnist/save2.tf',\\\n",
        "#                          custom_objects=\\\n",
        "#                           {\\\n",
        "#                               \"SquashLayer\": SquashLayer,\\\n",
        "#                               \"SafeNorm\": SafeNorm,\\\n",
        "#                               \"MyDigitCapsLayer\": MyDigitCapsLayer,\\\n",
        "#                               \"RoutingByAgreement\": RoutingByAgreement,\\\n",
        "#                               \"MyAccuracy\": MyAccuracy,\\\n",
        "#                               \"MarginLoss\": MarginLoss,\\\n",
        "#                           })\n",
        "# print(type(mm), mm.summary())\n",
        "# print(mm.weights[0][0][0][0][0:5])\n",
        "# e = mm.load_weights('/content/drive/MyDrive/WeightsMnist/latest_weights1.hdf5')\n",
        "# print(mm.weights[0][0][0][0][0:5])\n",
        "\n",
        "\n",
        "# Create the .tflite file\n",
        "# tflite_model_file = \"/content/drive/MyDrive/WeightsMnist/compressed.tflite\"\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(mm)\n",
        "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# converter.target_spec.supported_ops = [\n",
        "#   tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "#   tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "# ]\n",
        "\n",
        "# tflite_model = converter.convert()\n",
        "# with open(tflite_model_file, \"wb\") as f:\n",
        "#     f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1c026FiF3Hb"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVrB1GkTFItQ"
      },
      "source": [
        "!du -sh /content/drive/MyDrive/WeightsMnist/*\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTzAAQHpL51b"
      },
      "source": [
        "# Use this tutorial for pruning\n",
        "quantization has already been done earlier\n",
        "\n",
        "https://www.tensorflow.org/model_optimization/guide/pruning/pruning_with_keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUQtzXdBqPh6"
      },
      "source": [
        "PRUNING\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAVk1mxJqykT"
      },
      "source": [
        "pip install -q tensorflow-model-optimization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_DKdw7nqBI5",
        "outputId": "887e3998-50b7-435d-ce07-1f1972e3ddc0"
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "import tempfile\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# TODO: Remove this line\n",
        "mm = m\n",
        "print(\"ORIGINAL MODEL\")\n",
        "print(mm.summary())\n",
        "print('-' * 80)\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 128\n",
        "epochs = 2\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "num_images = x_train.shape[0] * (1 - validation_split)\n",
        "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=end_step)\n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "model_for_pruning = prune_low_magnitude(mm, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "\n",
        "model_for_pruning.summary()\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "######################################################################\n",
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "\n",
        "# Helper function uses `prune_low_magnitude` to make only the \n",
        "# Dense layers train with pruning.\n",
        "def apply_pruning_to_dense(layer):\n",
        "  print(\"called\")\n",
        "  if isinstance(layer, MyDigitCapsLayer):\n",
        "    print(f\"Layer {layer} {layer.name} slated for pruning\")\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
        "  elif layer.name == \"conv_layer_2\":\n",
        "    print(f\"Layer {layer} {layer.name} slated for pruning\")\n",
        "    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
        "  print(f\"Layer {layer} {layer.name} unchanged\")\n",
        "  return layer\n",
        "\n",
        "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
        "# to the layers of the model.\n",
        "model_for_pruning = tf.keras.models.clone_model(\n",
        "    mm,\n",
        "    clone_function=apply_pruning_to_dense,\n",
        ")\n",
        "print(model_for_pruning.summary())\n",
        "\n",
        "\"\"\"\n",
        "model_for_pruning = K.models.Sequential(\\\n",
        "              [\\\n",
        "                model_for_pruning,\\\n",
        "                MyReshapeLayer(),\\\n",
        "              ]\\\n",
        ")\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "model_for_pruning.compile(optimizer='adam', loss=MarginLoss(), metrics=[MyAccuracy()])\n",
        "#model_for_pruning.compile(optimizer='adam', loss=MarginLoss())\n",
        "\n",
        "model_for_pruning.fit(x_train, y_train,\n",
        "                  batch_size=32, epochs=2, validation_split=validation_split,\n",
        "                  callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ORIGINAL MODEL\n",
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
            "_________________________________________________________________\n",
            "conv_layer_2 (Conv2D)        (None, 6, 6, 256)         5308672   \n",
            "_________________________________________________________________\n",
            "reshape_layer_1 (Reshape)    (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps1_output_layer (SquashLa (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps2_predicted (MyDigitCaps (None, 1152, 10, 16, 1)   1474560   \n",
            "_________________________________________________________________\n",
            "routing1 (RoutingByAgreement (None, 1, 10, 16, 1)      11520     \n",
            "=================================================================\n",
            "Total params: 6,815,744\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "--------------------------------------------------------------------------------\n",
            "called\n",
            "Layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1633182c50> conv_layer_1 unchanged\n",
            "called\n",
            "Layer <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f1633114110> conv_layer_2 slated for pruning\n",
            "called\n",
            "Layer <tensorflow.python.keras.layers.core.Reshape object at 0x7f1633b2da90> reshape_layer_1 unchanged\n",
            "called\n",
            "Layer <__main__.SquashLayer object at 0x7f1633b7a910> caps1_output_layer unchanged\n",
            "called\n",
            "Layer <__main__.MyDigitCapsLayer object at 0x7f167fc2ba50> caps2_predicted slated for pruning\n",
            "called\n",
            "Layer <__main__.RoutingByAgreement object at 0x7f16200d5490> routing1 unchanged\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2191: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"my\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv_layer_1 (Conv2D)        (None, 20, 20, 256)       20992     \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv_lay (None, 6, 6, 256)         10617090  \n",
            "_________________________________________________________________\n",
            "reshape_layer_1 (Reshape)    (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "caps1_output_layer (SquashLa (None, 1152, 8)           0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_caps2_pr (None, 1152, 10, 16, 1)   2949122   \n",
            "_________________________________________________________________\n",
            "routing1 (RoutingByAgreement (None, 1, 10, 16, 1)      11520     \n",
            "=================================================================\n",
            "Total params: 13,598,724\n",
            "Trainable params: 6,815,744\n",
            "Non-trainable params: 6,782,980\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/2\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "   6/1688 [..............................] - ETA: 6:34 - loss: 2.3490 - my_accuracy_2: 0.0781WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0681s vs `on_train_batch_begin` time: 0.0822s). Check your callbacks.\n",
            "1688/1688 [==============================] - 147s 82ms/step - loss: 2.2801 - my_accuracy_2: 0.1505 - val_loss: 2.2761 - val_my_accuracy_2: 0.3202\n",
            "Epoch 2/2\n",
            " 504/1688 [=======>......................] - ETA: 1:32 - loss: 2.2791 - my_accuracy_2: 0.3390"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD9aZWk2D5Bh",
        "outputId": "2282a08c-1600-41f1-970d-48c6aae10f42"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU7MOJdAOcud"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}